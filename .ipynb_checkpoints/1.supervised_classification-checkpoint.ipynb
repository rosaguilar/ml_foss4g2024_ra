{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b54074be-fd7a-4ce6-a5a7-39857c71e5bd",
   "metadata": {},
   "source": [
    "## FOSS4G Belem - Brazil 2024\n",
    "## Workshop\n",
    "### Setting the scene - Machine learning  an intro\n",
    "\n",
    "**Dr. Rosa Aguilar**<br>\n",
    "r.aguilar@utwente.nl<br>\n",
    "https://www.linkedin.com/in/rosamaguilar/<br>\n",
    "\n",
    "**Part 1 - Supervised Classification** <br>\n",
    "\n",
    "In this notebook, we will execute a simple machine learning (ml) workflow.<br>\n",
    "We will classify a subset of a nine-band Sentinel-2 image using given reference data.\n",
    "The steps are as follows:\n",
    "<ol>\n",
    "    <li>Opening and visualizing the image to be classified</li>\n",
    "    <li>Extracting additional features, for example: a Enhanced Vegetation Index (EVI) and a  Water Index (NWI). A data cube will be created with the original image plus the extracted indices</li>\n",
    "    <li>Data sampling. We sample the data cube using the reference data. Two independent datasets will be created: a training dataset and a testing dataset. The training dataset will be used to train a ml algorithm whereas the testing dataset will be used to assess the performance of such algorithm</li>\n",
    "    <li>Training a ML model using the training dataset </li>\n",
    "    <li>Applying the trained model to the image and visualize the result</li>\n",
    "    <li>Reporting on the model performance</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b11fd21-fa50-4898-9c86-e07307fcb498",
   "metadata": {},
   "source": [
    "### 1. Opening and visualizing the image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc0aa57-2a52-4223-a59f-b43a104d085c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image file for 2020\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Any, Optional, Tuple\n",
    "from rasterio.plot import show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da845b7-5d6a-49ac-b353-3dd283617ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set some parameters for visualization\n",
    "NO_DATA = -9999\n",
    "NO_DATA_FLOAT = 0.0001\n",
    "PERCENTILES = (0.1, 99.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf59ef97-71b9-43f5-bca1-6478e0d2732f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentinel-2 image bands [0:B02, 1:B03, 2:B04, 3:B05, 4:B06, 5:B07, 6:B08, 7:B11, 8:B12]\n",
    "# reads the raster and return an array\n",
    "def load_raster(path, crop=None):\n",
    "    with rasterio.open(path) as src:\n",
    "        img = src.read()\n",
    "\n",
    "        # load first 6 bands\n",
    "        img = img[:9]\n",
    "\n",
    "        img = np.where(img == NO_DATA, NO_DATA_FLOAT, img)\n",
    "        if crop:\n",
    "            img = img[:, -crop[0]:, -crop[1]:]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6fc978-0cfb-497f-950b-e1ae848b1bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function\n",
    "path = './belem/sentinel_Belem38_20200907.tif'\n",
    "raster = load_raster(path)\n",
    "# cherckpoint\n",
    "raster.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fcdbbc-0673-43b6-83f8-24fbcb1eed0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normaliza pixel values between 0 and 1\n",
    "def normalize_band(band):\n",
    "    return (band - np.min(band))/ (np.max(band) - np.min(band))\n",
    "\n",
    "# defines a function to plot an image in RGB format\n",
    "# by default the combination is 432\n",
    "def plot_image(\n",
    "    image: np.ndarray,\n",
    "    factor: float = 1,\n",
    "    bands: list = [2, 1, 0],\n",
    "    clip_range: Optional[Tuple[float, float]] = None,\n",
    "    **kwargs: Any\n",
    ") -> None:\n",
    "    \"\"\"Utility function for plotting RGB images.\"\"\"\n",
    "    raster =  copy.deepcopy(image)\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 10))\n",
    "\n",
    "    \n",
    "    # get the bands for the RGB combination\n",
    "    bandR = raster[bands[0],:,:]\n",
    "    bandG = raster[bands[1],:,:]\n",
    "    bandB = raster[bands[2],:,:]\n",
    "\n",
    "    # get normalized bands\n",
    "    bandR_norm = normalize_band(bandR)\n",
    "    bandG_norm = normalize_band(bandG)\n",
    "    bandB_norm = normalize_band(bandB)\n",
    "\n",
    "    # stack bands RGB = 432\n",
    "    simage = np.dstack((bandR_norm, bandG_norm, bandB_norm))\n",
    "\n",
    "    if clip_range is not None:\n",
    "        ax.imshow(np.clip(simage * factor, *clip_range), **kwargs)\n",
    "    else:\n",
    "        ax.imshow(simage * factor, **kwargs)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(f'RGB Composite Bands {bands}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c8f24c-7e23-4d13-b39d-f1c277bcb0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the image\n",
    "plot_image(raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfd4928-5311-45be-bea4-fb6d1cd5f9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a 8 4 3 - urban applications\n",
    "plot_image(raster, bands=[6,2,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42b79f9-bc78-490e-8216-434a84a42c4f",
   "metadata": {},
   "source": [
    "### 2. Feature extraction\n",
    "Calculating EVI and NDWI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e79570b-2323-40c7-81b7-68ea6dcf7b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute indices \n",
    "# Extract the  bands [0:B02, 1:B03, 2:B04, 3:B05, 4:B06, 5:B07, 6:B08, 7:B11, 8:B12]\n",
    "B2 = raster[0, :, :]  # B02 (Blue)\n",
    "B3 = raster[1, :, :]  # B03 (Green)\n",
    "B4 = raster[2, :, :]  # B04 (Red)\n",
    "B8 = raster[6, :, :]  # B08 (NIR)\n",
    "\n",
    "# calculate NDWI NDWI = (Green - NIR) / (Green + NIR)\n",
    "NDWI = (B3 - B8) / (B3 + B8)\n",
    "\n",
    "# calculate EVI -->  EVI = G * (B8 - B4) / (B8 + C1 * B4 - C2 * B2 + L)\n",
    "G = 2.5    # Gain factor\n",
    "C1 = 6.0   # Coefficient for the red band\n",
    "C2 = 7.5   # Coefficient for the blue band\n",
    "L = 1.0    # Canopy background adjustment\n",
    "# Create the divisor \n",
    "DIVISOR = (B8 + C1 * B4 - C2 * B2 + L)\n",
    "# EVI = G * (B8 - B4) / (B8 + C1 * B4 - C2 * B2 + L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb78ba4c-3ac0-4214-a3ad-4e288b209006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAN feature treatment - # imputing nan values using the mean\n",
    "# imputing nan values\n",
    "\n",
    "EVI = np.where(DIVISOR != 0, G * (B8 - B4) / DIVISOR, np.nan)\n",
    "EVI_mean = np.nanmean(EVI)\n",
    "EVI = np.where(~np.isnan(EVI), EVI, EVI_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e080859-a90c-473d-a946-44dbe6531917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check nan values\n",
    "np.sum(np.isnan(EVI)), np.sum(np.isnan(NDWI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eae563f-f08c-4782-92ee-0a8d0f7e2416",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1b8546-c705-4ed5-8fff-dc9f7636d104",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# normalize each band of the raster\n",
    "channels = []\n",
    "for i in range(0, raster.shape[0]):\n",
    "    band = normalize_band(raster[i,:,:])\n",
    "    channels.append(band)\n",
    "\n",
    "# normalize indices\n",
    "EVI = normalize_band(EVI)\n",
    "NDWI = normalize_band(NDWI)\n",
    "\n",
    "# append the indices to the list\n",
    "channels.append(EVI)\n",
    "channels.append(NDWI)\n",
    "\n",
    "# stack the layers to create a data cube\n",
    "datacube = np.stack(channels)\n",
    "datacube.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b016e526-e193-4d8e-97fc-f93dd33bd7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the datacube aka as expanded image\n",
    "# open the original raster to get the metadata\n",
    "meta = None\n",
    "with rasterio.open(path) as src:\n",
    "    if meta is None:\n",
    "        meta = src.meta.copy()\n",
    "        meta.update(count=0)  # Initialize with no bands\n",
    "\n",
    "# update the band count\n",
    "meta.update(count=datacube.shape[0])\n",
    "meta.update(dtype ='float32')\n",
    "# Path to save the output GeoTIFF\n",
    "output_path = './belem/image_stacked2020.tif'\n",
    "\n",
    "# Write the stacked array to the new GeoTIFF file\n",
    "with rasterio.open(output_path, 'w', **meta) as dst:\n",
    "    for i in range(datacube.shape[0]):\n",
    "        dst.write(datacube[i, :, :], i + 1)\n",
    "\n",
    "print(f\"Stacked GeoTIFF with additional bands saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24276dc0-b24c-42e7-87fc-79119f2f01d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install folium matplotlib mapclassify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9066d35-b34a-4685-95b7-468e70dc968e",
   "metadata": {},
   "source": [
    "### 3.Sampling the image to obtain training and testing datasets\n",
    "\n",
    "We will use reference points where the land cover is known. Using these coordinates we will sample the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418dc5e9-1387-4219-9572-26eb426ce00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the geodataset\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "gdf = gpd.read_file(\"gt_2020.shp\")\n",
    "gdf.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6811922e-de27-46be-9dbb-db05dce7e2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get info about the geodataframe\n",
    "gdf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a77f1c8-9e92-4837-b9b2-38d01f0a5f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list with the coordinates\n",
    "coord_list = [(x,y) for x,y in zip(gdf['geometry'].x, gdf['geometry'].y)]\n",
    "\n",
    "# check point - get the first three coordinates\n",
    "coord_list [:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39a5a4a-d557-457b-83a4-c2bb86685f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the recent created raster dataset\n",
    "datacube_src = rasterio.open(output_path)\n",
    "show(datacube_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd27442-4664-4723-8330-ad473b028b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "datacube_src.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7ab840-5220-4139-a0bb-67078cf864e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the points on top of the raster\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# transform rasterio plot to real world coords\n",
    "extent=[datacube_src.bounds[0], datacube_src.bounds[2], datacube_src.bounds[1], datacube_src.bounds[3]]\n",
    "ax = rasterio.plot.show(datacube_src, extent=extent, ax=ax)   #, cmap='pink'\n",
    "\n",
    "gdf.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75309a46-e386-4a87-959e-d73630d278ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [x for x in datacube_src.sample(coord_list)]\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cc59c1-d47a-4c99-86a7-3413fc91738a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append the pixel data values to the reference data\n",
    "gdf['pixels'] = data\n",
    "gdf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befcd6b3-29a8-4511-86f5-ec2c08765c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the columns \n",
    "# [0:B02, 1:B03, 2:B04, 3:B05, 4:B06, 5:B07, 6:B08, 7:B11, 8:B12, 9:EVI, 10: NDWI]\n",
    "def single_value(x, k):\n",
    "    index = columns_index[k]\n",
    "    return x[index]\n",
    "\n",
    "columns_index = {'B2': 0,'B3':1, 'B4':2, 'B5':3, 'B6':4, 'B7':5, 'B8':6,\n",
    "                'B11':7, 'B12':8, 'EVI':9, 'NDWI':10}\n",
    "\n",
    "for k in columns_index.keys():\n",
    "    gdf[k] = gdf.apply(lambda x: single_value(x['pixels'], k), axis =1 )\n",
    "gdf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0974d7b7-1464-44ba-bdc2-5e5e2f048f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the pixels column\n",
    "gdf.drop(columns=['pixels'], inplace=True)\n",
    "gdf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb440fd-a6cf-46b3-8f08-fc5b61cdcb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# get the training and testing dataset\n",
    "columns_out = ['id', 'lc', 'geometry']\n",
    "cols_sample = [x for x in gdf.columns if x not in columns_out]\n",
    "X = gdf[cols_sample]\n",
    "Y = gdf['lc']\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
    "print(xtrain.shape, xtest.shape)\n",
    "print(ytrain.shape, ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bb2176-9467-460b-bcc4-7a2809ac91a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d8ef16-ab25-4b19-80c3-2d7c0361b20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=300, criterion=\"gini\", max_depth=None, bootstrap=True, min_samples_split=2, n_jobs=1)\n",
    "rf.fit(xtrain, ytrain)\n",
    "ypred = rf.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249192c6-01c3-4f52-965d-a477721af251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the most important features\n",
    "feature_names = cols_sample\n",
    "importances = rf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)\n",
    "forest_importances = pd.Series(importances, index=feature_names)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "ax.set_title(\"Feature importances\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1154a75-ad84-42e5-a8cb-b45d22cfdc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint bandcount\n",
    "meta = datacube_src.meta\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078dc032-5493-4b2b-9011-ce4dc0597fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the data in the form required for the algorithms\n",
    "\n",
    "channels = []\n",
    "for i in range(datacube_src.meta['count']):\n",
    "    band = datacube_src.read(i+1)\n",
    "    channels.append(band.ravel())\n",
    "image_exp = np.stack(channels, axis =1)\n",
    "image_exp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b39120-5a46-402d-9757-de83d162b77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying RF to the image\n",
    "\n",
    "pred_image2 = rf.predict(image_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bae931b-692c-4ac4-b124-9c582318de09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reshape the result\n",
    "result = pred_image2.reshape(datacube_src.shape)\n",
    "show(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42aac85f-726e-47ec-bae3-b1943df765b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the prediction/result\n",
    "# open the original raster to get the metadata\n",
    "meta = None\n",
    "with rasterio.open(path) as src:\n",
    "    if meta is None:\n",
    "        meta = src.meta.copy()\n",
    "        meta.update(count=0)  # Initialize with no bands\n",
    "\n",
    "# update the band count\n",
    "meta.update(count=1)\n",
    "# Path to save the output GeoTIFF\n",
    "output_path = './belem/image_class2020.tif'\n",
    "\n",
    "# Write the stacked array to the new GeoTIFF file\n",
    "with rasterio.open(output_path, 'w', **meta) as dst:\n",
    "    dst.write(result[:,:],1)\n",
    "\n",
    "print(f\"Classified image saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849c278e-e0e3-4ad0-84f0-9127c340103b",
   "metadata": {},
   "source": [
    "### 6. Reporting the error\n",
    "A. a graph with real values vs prediction <br> and\n",
    "B. The confusion matrix, overall accuracy and F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fbe846-0920-423f-a9b9-430252161fc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Error per point\n",
    "import seaborn as sns\n",
    "x = np.arange(0,ytest.shape[0],1)\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.plot(x, ytest,'bo', label='actual target')\n",
    "plt.plot(x, ypred, 'r+', label='predicted target' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a0b447-0b0c-4eb3-9237-59cac521b403",
   "metadata": {},
   "source": [
    "### 6. Report the error\n",
    "Confusion Matrix, Overal accuracy and F1 score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc8925e-daf6-48b8-b57f-aa56096c440e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a78091-b01a-47e5-ae06-897248caf40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfm = confusion_matrix(ypred, ytest)\n",
    "f1 = f1_score(ypred, ytest, average='micro')\n",
    "print(f\"f1_score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4659a1b-38d6-460a-9943-0e973c71537b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the CFM\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cfm,\n",
    "                              display_labels=rf.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109c6280-bb9c-4237-a5de-36133a7d33a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf['lc'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b800ca-0841-4bad-8709-660785866e75",
   "metadata": {},
   "source": [
    "We implement a whole workflow with random forest.\n",
    "\n",
    "There are other algorithms that might perform better.\n",
    "The cells below execute a Gradient Boosting Classifier.\n",
    "Depending on the problem certain algorithms perform better than the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2826d7da-de07-44ae-8044-079193440dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying - GradientBoostingClassifier\n",
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(xtrain, ytrain)\n",
    "ypred = gb.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639c1c48-792d-43b0-9e98-ef1c22f4edfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfm_gb = confusion_matrix(ypred, ytest)\n",
    "f1_gb = f1_score(ypred, ytest, average='micro')\n",
    "print(f\"f1_score: {f1_gb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d29446f-958a-494a-be43-9201e3deb65c",
   "metadata": {},
   "source": [
    "###  Task\n",
    "Do the same workflow (complete analysis) for the image of 2023\n",
    "*22M_20230101-20240101_lc.tiff*, the training data is given in the file *gt_2023.shp*. \n",
    "\n",
    "Having the two results, you can evaluate the dynamic in land cover in the area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3341218e-637c-4b28-9603-85a0827c472d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0ea6bb-cd3c-49a1-8743-0e1be940007f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
